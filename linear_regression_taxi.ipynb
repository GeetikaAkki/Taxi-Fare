{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bc927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from numpy import array, arange, linspace, mean, std  \n",
    "from pandas import DataFrame, read_csv  \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense \n",
    "from plotly.express import scatter, bar, line  \n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objects import Figure, Scatter, Bar  \n",
    "from seaborn import heatmap, pairplot  \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import keras as keras\n",
    "import nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_taxi_dataset = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/chicago_taxi_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e9f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = chicago_taxi_dataset[['TRIP_MILES', 'TRIP_SECONDS', 'FARE', 'COMPANY', 'PAYMENT_TYPE', 'TIP_RATE']]\n",
    "\n",
    "print('Read dataset completed successfully.')\n",
    "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
    "training_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
    "training_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_fare = training_df['FARE'].max()\n",
    "print(\"What is the maximum fare? \\t\\t\\t\\tAnswer: ${fare:.2f}\".format(fare = max_fare))\n",
    "\n",
    "mean_distance = training_df['TRIP_MILES'].mean()\n",
    "print(\"What is the mean distance across all trips? \\t\\tAnswer: {mean:.4f} miles\".format(mean = mean_distance))\n",
    "\n",
    "num_unique_companies =  training_df['COMPANY'].nunique()\n",
    "print(\"How many cab companies are in the dataset? \\t\\tAnswer: {number}\".format(number = num_unique_companies))\n",
    "\n",
    "most_freq_payment_type = training_df['PAYMENT_TYPE'].value_counts().idxmax()\n",
    "print(\"What is the most frequent payment type? \\t\\tAnswer: {type}\".format(type = most_freq_payment_type))\n",
    "\n",
    "missing_values = training_df.isnull().sum().sum()\n",
    "print(\"Are any features missing data? \\t\\t\\t\\tAnswer:\", \"No\" if missing_values == 0 else \"Yes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9ff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(training_df, x_vars=[\"FARE\", \"TRIP_MILES\", \"TRIP_SECONDS\"], y_vars=[\"FARE\", \"TRIP_MILES\", \"TRIP_SECONDS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(df, feature_names, label_name, model_output, sample_size=200):\n",
    "\n",
    "  random_sample = df.sample(n=sample_size).copy()\n",
    "  random_sample.reset_index()\n",
    "  weights, bias, epochs, rmse = model_output\n",
    "\n",
    "  is_2d_plot = len(feature_names) == 1\n",
    "  model_plot_type = \"scatter\" if is_2d_plot else \"surface\"\n",
    "  fig = make_subplots(rows=1, cols=2,\n",
    "                      subplot_titles=(\"Loss Curve\", \"Model Plot\"),\n",
    "                      specs=[[{\"type\": \"scatter\"}, {\"type\": model_plot_type}]])\n",
    "\n",
    "  plot_data(random_sample, feature_names, label_name, fig)\n",
    "  plot_model(random_sample, feature_names, weights, bias, fig)\n",
    "  plot_loss_curve(epochs, rmse, fig)\n",
    "\n",
    "  fig.show()\n",
    "  return\n",
    "\n",
    "def plot_loss_curve(epochs, rmse, fig):\n",
    "  curve = px.line(x=epochs, y=rmse)\n",
    "  curve.update_traces(line_color='#ff0000', line_width=3)\n",
    "\n",
    "  fig.append_trace(curve.data[0], row=1, col=1)\n",
    "  fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
    "  fig.update_yaxes(title_text=\"Root Mean Squared Error\", row=1, col=1, range=[rmse.min()*0.8, rmse.max()])\n",
    "\n",
    "  return\n",
    "\n",
    "def plot_data(df, features, label, fig):\n",
    "  if len(features) == 1:\n",
    "    scatter = px.scatter(df, x=features[0], y=label)\n",
    "  else:\n",
    "    scatter = px.scatter_3d(df, x=features[0], y=features[1], z=label)\n",
    "\n",
    "  fig.append_trace(scatter.data[0], row=1, col=2)\n",
    "  if len(features) == 1:\n",
    "    fig.update_xaxes(title_text=features[0], row=1, col=2)\n",
    "    fig.update_yaxes(title_text=label, row=1, col=2)\n",
    "  else:\n",
    "    fig.update_layout(scene1=dict(xaxis_title=features[0], yaxis_title=features[1], zaxis_title=label))\n",
    "\n",
    "  return\n",
    "\n",
    "def plot_model(df, features, weights, bias, fig):\n",
    "  df['FARE_PREDICTED'] = bias[0]\n",
    "\n",
    "  for index, feature in enumerate(features):\n",
    "    df['FARE_PREDICTED'] = df['FARE_PREDICTED'] + weights[index][0] * df[feature]\n",
    "\n",
    "  if len(features) == 1:\n",
    "    model = px.line(df, x=features[0], y='FARE_PREDICTED')\n",
    "    model.update_traces(line_color='#ff0000', line_width=3)\n",
    "  else:\n",
    "    z_name, y_name = \"FARE_PREDICTED\", features[1]\n",
    "    z = [df[z_name].min(), (df[z_name].max() - df[z_name].min()) / 2, df[z_name].max()]\n",
    "    y = [df[y_name].min(), (df[y_name].max() - df[y_name].min()) / 2, df[y_name].max()]\n",
    "    x = []\n",
    "    for i in range(len(y)):\n",
    "      x.append((z[i] - weights[1][0] * y[i] - bias[0]) / weights[0][0])\n",
    "\n",
    "    plane=pd.DataFrame({'x':x, 'y':y, 'z':[z] * 3})\n",
    "\n",
    "    light_yellow = [[0, '#89CFF0'], [1, '#FFDB58']]\n",
    "    model = go.Figure(data=go.Surface(x=plane['x'], y=plane['y'], z=plane['z'],\n",
    "                                      colorscale=light_yellow))\n",
    "\n",
    "  fig.add_trace(model.data[0], row=1, col=2)\n",
    "\n",
    "  return\n",
    "\n",
    "def model_info(feature_names, label_name, model_output):\n",
    "  weights = model_output[0]\n",
    "  bias = model_output[1]\n",
    "\n",
    "  nl = \"\\n\"\n",
    "  header = \"-\" * 80\n",
    "  banner = header + nl + \"|\" + \"MODEL INFO\".center(78) + \"|\" + nl + header\n",
    "\n",
    "  info = \"\"\n",
    "  equation = label_name + \" = \"\n",
    "\n",
    "  for index, feature in enumerate(feature_names):\n",
    "    info = info + \"Weight for feature[{}]: {:.3f}\\n\".format(feature, weights[index][0])\n",
    "    equation = equation + \"{:.3f} * {} + \".format(weights[index][0], feature)\n",
    "\n",
    "  info = info + \"Bias: {:.3f}\\n\".format(bias[0])\n",
    "  equation = equation + \"{:.3f}\\n\".format(bias[0])\n",
    "\n",
    "  return banner + nl + info + nl + equation\n",
    "\n",
    "print(\"SUCCESS: defining plotting functions complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5990cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(my_learning_rate, num_features):\n",
    " \n",
    "  inputs = keras.Input(shape=(num_features,))\n",
    "  outputs = keras.layers.Dense(units=1)(inputs)\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "def train_model(model, features, label, epochs, batch_size):\n",
    "\n",
    "\n",
    "\n",
    "  history = model.fit(x=features,\n",
    "                      y=label,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)\n",
    "\n",
    "\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "\n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history) \n",
    "\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return trained_weight, trained_bias, epochs, rmse\n",
    "\n",
    "\n",
    "def run_experiment(df, feature_names, label_name, learning_rate, epochs, batch_size):\n",
    "\n",
    "  print('INFO: starting training experiment with features={} and label={}\\n'.format(feature_names, label_name))\n",
    "\n",
    "  num_features = len(feature_names)\n",
    " \n",
    "  features = df.loc[:, feature_names].values\n",
    "  label = df[label_name].values\n",
    "\n",
    "  model = build_model(learning_rate, num_features)\n",
    "  model_output = train_model(model, features, label, epochs, batch_size)\n",
    "\n",
    "  print('\\nSUCCESS: training experiment complete\\n')\n",
    "  print('{}'.format(model_info(feature_names, label_name, model_output)))\n",
    "  make_plots(df, feature_names, label_name, model_output)\n",
    "\n",
    "  return model\n",
    "\n",
    "print(\"SUCCESS: defining linear regression functions complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e49f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "# Specify the feature and the label.\n",
    "features = ['TRIP_MILES']\n",
    "label = 'FARE'\n",
    "\n",
    "model_1 = run_experiment(training_df, features, label, learning_rate, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adeba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "training_df.loc[:, 'TRIP_MINUTES'] = training_df['TRIP_SECONDS']/60\n",
    "\n",
    "features = ['TRIP_MILES', 'TRIP_MINUTES']\n",
    "label = 'FARE'\n",
    "\n",
    "model_2 = run_experiment(training_df, features, label, learning_rate, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d15c34",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
